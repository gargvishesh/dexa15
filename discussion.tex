\section{Query Optimizer Integration}
\label{discussion}

In the earlier sections, given a user query, the standard plan choice
of the PostgreSQL optimizer was used even with the modified operator
implementations. That is, while the execution engine was PCM-conscious,
the presence of PCM was completely \emph{opaque} to the optimizer.
Given the read-write asymmetry of PCM in terms of both latency and wear
factor, it is possible that alternative plans, capable of providing better
performance profiles, may exist in the plan search space. To discover
such plans, the database query optimizer needs to incorporate PCM
awareness in both the operator cost models and the plan enumeration
algorithms.

The current optimizers choose plans using just a latency based costing mechanism. We introduce a new metric of \emph{write cost} in the operator cost model, representing the incurred writes for a plan, using the estimators described in Sections~\ref{sort} to \ref{gby}. The existing latency based cost models of the operators are also revised to account for the additional latency incurred during writes. We henceforth refer to the write cost and the latency cost of a plan as WC and LC, respectively. 

We redesign the query optimizer to now allow a user defined parameter which we call the \emph{slack} denoted by $\lambda$. The slack represents the maximum relative slowdown, compared to the LC-optimal query plan, that is acceptable to the user in lieu of getting better write performance. That is, if the LC of the LC-optimal execution plan $P_o$ is $c_o$ and the LC of an alternate plan $P_i$ is $c_i$, the user is willing to accept $P_i$ as the final execution plan if $c_i \le (1+\lambda c_o)$. The $P_i$ with the least WC satisfying this equation is considered the WC-optimal plan.

During the plan enumeration process in the planning phase, the native optimizer propagates the LC-optimal and interesting order plans through the internal nodes of the dynamic programming lattice. This can lead to pruning of potential WC-optimal plans. Propagating the \emph{entire} list of sub-plans at each internal node, on the other hand, can end up with an exponential search space at the root node. We use a heuristic propagation mechanism at each internal node using an algorithmic parameter \emph{local threshold} $\lambda_l$ ($\ge\lambda$). Let  $P_i^'$ and $P_o^'$ be a sub-plan and the LC-optimal sub-plan at a node, respectively, with $c_i^'$ and $c_o^'$ being their corresponding LC values. Now, along with the LC-optimal and interesting order sub-plans, we also propagate $P_i^'$ with the least WC that satisfies $c_i^{'} \le (1+\lambda_l c_o^{'})$. We observed that keeping $\lambda_l = \lambda$ gave reasonably good results in this regard.

In the light of these modifications, let
us revisit Query Q13, for which the default plan was shown in
Figure~\ref{fig:plan_trees}(a). With the $\lambda$ value of 0 indicating no slack being allowed, we got a new execution plan wherein the
merge left join between the \textit{customer} and \textit{orders}
tables is replaced by a hash left join. This indicates the immediate impact of revised latency costs after including the additional write latency.

The relative performance of
these two alternatives with regard to PCM Writes and Cycles, are shown
in Figures~\ref{fig:perf_comp}(a) and (b), respectively. We observe
here that there is a \emph{huge difference} in both the query response times as well as writes overheads for both the plans.
Specifically, the alternative plan reduces the writes by well over an
order of magnitude!
As we gradually increased the value of slack, we didn't notice any change in plans. When the slack was made to be as large as 5, we observed that the hash left join gave way to nested loop left join, clearly indicating that it gives write savings at a steep latency cost.


\begin{figure}[htbp]
\centering
	
\subfloat[Performance of Alternative Plans]{
\includegraphics[height=29mm]{q13_alternate_plan.png}
}

\subfloat[Overall performance comparison]{
\begin{small}

  \begin{tabular}{p{2cm}p{2cm}p{2cm}p{2cm}p{2cm}}
  \toprule                                                                                                
  
  \textbf{Metric} & \textbf{Opt(PCM-O) Exec(PCM-O) } & \textbf{Opt(PCM-O) Exec(PCM-C)} & \textbf{Opt(PCM-C) Exec(PCM-C)} & \textbf{Opt(PCM-C) Exec(PCM-O)}\\
  \midrule                                                                                                
  
  \textbf{Writes(words)} &  $233.6 \times 10^6$ & $110.6 \times 10^6$ & $4.66 \times 10^6$ & $12.8 \times 10^6$\\ 
  \textbf{Cycles} &  $13.1 \times 10^9$ & $10.4 \times 10^9$ & $3.2 \times 10^9$ & $4.5 \times 10^9$\\ 
  \bottomrule                                                                                             
  \end{tabular}                                                                                           
\end{small}                                                                                           
}
\caption{Performance comparison}
\label{fig:perf_comp}
\end{figure}



To put matters into perspective, Figure~\ref{fig:perf_comp}(b) summarizes
the relative performance benefits obtained as the database layers are
gradually made PCM-conscious (in the figure, the labels Opt and Exec refer to Optimizer and Executor, respectively, while PCM-O and PCM-C
refer to PCM-Oblivious and PCM-Conscious, respectively). For the sake of completeness, we have also added results for the case when the Optimizer is PCM-C but the Executor is PCM-O (last column). The results clearly indicate that future query optimizers for PCM-based architectures need to incorporate PCM-Consciousness at \emph{both} the Optimizer and the Executor level in order to get the best performance while executing a given query.




\begin{comment}
\begin{figure}[h]
	%\centering
	\subfloat[Database layers]{
	\includegraphics[width=4cm]{db_levels.png}
	}
   	\subfloat[Q13 alternate plan]{
   	\begin{tikzpicture}[scale=., transform shape]

\tikzstyle{every node} = [rectangle, fill=gray!5]

\node (d) at (0,3) {Index Scan / Filter};
\node (c) at (0,1.5) {CUSTOMER};

\node (s) at (3,3) {Hash};
\node (p) at (3,2.25) {Seq. Scan / Filter};
\node (a) at (3,1.5) {ORDERS};

\node (e) at (1.5,4) {Hash Left Join};
\node (f) at (1.5,5)  {Group Aggregate};
\node (g) at (1.5,6)  {Hash Aggregate};
\node (h) at (1.5,7)  {Sort};


\draw[-] (c) -- (d);
\draw[-] (a) -- (p);
\draw[-] (d) -- (e);
\draw[-] (p) -- (s);
\draw[-] (s) -- (e);
\draw[-] (e) -- (f);

\draw[-] (f) -- (g);
\draw[-] (g) -- (h);

\end{tikzpicture}
   	}
  %\centering                                                                                             

\caption{Alternative Execution Plans for Query Q13}
	\label{fig:layers}
	
\end{figure}
\end{comment}